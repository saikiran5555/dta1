{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "433edff5",
   "metadata": {},
   "source": [
    "The confusion matrix is a table that is used to evaluate the performance of a classification model, providing a detailed breakdown of the model's predictions compared to the actual outcomes. It is particularly useful for assessing the performance of a classification algorithm on a set of data for which the true class labels are known. The confusion matrix consists of four main components:\n",
    "\n",
    "True Positive (TP):\n",
    "\n",
    "Instances that are actually positive (belong to the positive class) and are correctly predicted as positive by the model.\n",
    "True Negative (TN):\n",
    "\n",
    "Instances that are actually negative (belong to the negative class) and are correctly predicted as negative by the model.\n",
    "False Positive (FP):\n",
    "\n",
    "Instances that are actually negative but are incorrectly predicted as positive by the model. Also known as a Type I error or a false alarm.\n",
    "False Negative (FN):\n",
    "\n",
    "Instances that are actually positive but are incorrectly predicted as negative by the model. Also known as a Type II error or a miss.\n",
    "The confusion matrix is typically represented as follows:\n",
    "\n",
    "mathematica\n",
    "Copy code\n",
    "            | Predicted Negative | Predicted Positive |\n",
    "Actual Negative |        TN          |        FP          |\n",
    "Actual Positive |        FN          |        TP          |\n",
    "From the confusion matrix, various performance metrics can be derived:\n",
    "\n",
    "Accuracy (ACC):\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "ACC= \n",
    "TP+TN+FP+FN\n",
    "TP+TN\n",
    "​\n",
    " \n",
    "Accuracy measures the overall correctness of the model's predictions.\n",
    "\n",
    "Precision (PPV, Positive Predictive Value):\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "Precision= \n",
    "TP+FP\n",
    "TP\n",
    "​\n",
    " \n",
    "Precision focuses on the accuracy of positive predictions and is relevant when minimizing false positives is crucial.\n",
    "\n",
    "Recall (Sensitivity, True Positive Rate):\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "Recall= \n",
    "TP+FN\n",
    "TP\n",
    "​\n",
    " \n",
    "Recall emphasizes the ability of the model to capture all positive instances and is relevant when minimizing false negatives is important.\n",
    "\n",
    "F1 Score:\n",
    "�\n",
    "1\n",
    " Score\n",
    "=\n",
    "2\n",
    "×\n",
    "Precision\n",
    "×\n",
    "Recall\n",
    "Precision\n",
    "+\n",
    "Recall\n",
    "F1 Score= \n",
    "Precision+Recall\n",
    "2×Precision×Recall\n",
    "​\n",
    " \n",
    "The F1 Score is the harmonic mean of precision and recall, providing a balance between the two.\n",
    "\n",
    "Specificity (True Negative Rate):\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "Specificity= \n",
    "TN+FP\n",
    "TN\n",
    "​\n",
    " \n",
    "Specificity focuses on the ability of the model to correctly identify negative instances.\n",
    "\n",
    "False Positive Rate (FPR):\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "FPR= \n",
    "TN+FP\n",
    "FP\n",
    "​\n",
    " \n",
    "FPR measures the proportion of actual negatives incorrectly classified as positives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
